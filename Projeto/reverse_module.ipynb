{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import socket\n",
    "import requests\n",
    "import dns.resolver\n",
    "import time\n",
    "\n",
    "# Função para obter o IP de um domínio\n",
    "def get_ip(domain):\n",
    "    try:\n",
    "        print (socket.gethostbyname(domain))\n",
    "        return socket.gethostbyname(domain)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Função para obter a localização do IP usando a API ipinfo.io\n",
    "def get_location(ip):\n",
    "    if ip:\n",
    "        try:\n",
    "            response = requests.get(f'https://ipinfo.io/{ip}/json?token=b90bb6976ece63')\n",
    "            data = response.json()\n",
    "            print(\"Aqui\",data)\n",
    "            loc = data.get('loc', '').split(',')\n",
    "            latitude = loc[0] if len(loc) > 0 else ''\n",
    "            longitude = loc[1] if len(loc) > 1 else ''\n",
    "            return {\n",
    "                'city': data.get('city', ''),\n",
    "                'region': data.get('region', ''),\n",
    "                'country': data.get('country', ''),\n",
    "                'org': data.get('org', ''),\n",
    "                'postal': data.get('postal', ''),\n",
    "                'timezone': data.get('timezone', ''),\n",
    "                'hostname': data.get('hostname', ''),\n",
    "                'latitude': latitude,\n",
    "                'longitude': longitude,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'city': '',\n",
    "                'region': '',\n",
    "                'country': '',\n",
    "                'org': '',\n",
    "                'postal': '',\n",
    "                'timezone': '',\n",
    "                'hostname': '',\n",
    "                'latitude': '',\n",
    "                'longitude': '',\n",
    "            }\n",
    "    return {\n",
    "        'city': '',\n",
    "        'region': '',\n",
    "        'country': '',\n",
    "        'org': '',\n",
    "        'postal': '',\n",
    "        'timezone': '',\n",
    "        'hostname': '',\n",
    "        'latitude': '',\n",
    "        'longitude': '',\n",
    "    }\n",
    "\n",
    "# Função para obter o DNS reverso de um IP\n",
    "def get_reverse_dns(ip):\n",
    "    if ip:\n",
    "        try:\n",
    "            return socket.gethostbyaddr(ip)[0]\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Função para obter o número de registros DNS de um IP\n",
    "def get_dns_count(ip):\n",
    "    if ip:\n",
    "        try:\n",
    "            answers = dns.resolver.resolve(ip, 'A')\n",
    "            return len(answers)\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Já corridos: \n",
    "    -dataset1_block6\n",
    "\n",
    "A correr:\n",
    "    -teste\n",
    "'''\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv('Datasets/teste.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linhas em que a label não se encontra preenchida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      " 1.0    3210\n",
      " 0.0    2256\n",
      "-1.0      34\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_16364\\2910599684.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['label'].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Substituir valores vazios na coluna \"label\" por -1\n",
    "df['label'].fillna(-1, inplace=True)\n",
    "\n",
    "# Contar os valores únicos na coluna \"label\"\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Encontrar os índices das linhas com valor -1 na coluna \"label\"\n",
    "indices_to_drop = df[df['label'] == -1].index\n",
    "\n",
    "# Remover as linhas com valor -1 na coluna \"label\"\n",
    "df.drop(indices_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse module DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.74.194.252\n",
      "77.222.40.61\n",
      "142.250.178.179\n",
      "162.159.138.44\n",
      "23.223.95.149\n",
      "3.160.132.4\n",
      "104.21.10.118\n",
      "23.47.189.169\n",
      "143.106.176.32\n",
      "141.193.213.20\n",
      "23.47.188.211\n",
      "51.255.25.209\n",
      "85.13.161.17\n",
      "104.26.11.49\n",
      "35.170.23.0\n",
      "194.195.220.161\n",
      "141.193.213.11\n",
      "72.52.135.95\n",
      "34.149.87.45\n",
      "23.227.38.74\n",
      "94.142.246.101\n",
      "199.60.103.225\n",
      "62.210.243.12\n",
      "70.35.202.183\n",
      "23.227.38.32\n",
      "91.238.161.176\n",
      "104.26.2.2\n",
      "23.185.0.1\n",
      "195.246.109.168\n",
      "141.138.137.134\n",
      "199.60.103.254\n",
      "172.67.148.142\n",
      "23.227.38.74\n",
      "193.58.164.195\n",
      "3.72.140.173\n",
      "155.185.254.142\n",
      "172.67.153.140\n",
      "3.110.7.154\n",
      "178.128.142.63\n",
      "23.227.38.74\n",
      "199.60.103.225\n",
      "81.169.145.171\n",
      "172.67.13.247\n",
      "193.34.145.203\n",
      "137.52.141.34\n",
      "154.206.135.145\n",
      "172.64.152.227\n",
      "69.163.183.43\n",
      "3.160.132.125\n",
      "66.165.237.162\n",
      "20.185.103.200\n",
      "104.21.8.209\n",
      "69.163.181.31\n",
      "89.44.120.139\n",
      "159.223.7.43\n",
      "13.107.246.42\n",
      "45.152.249.9\n",
      "107.178.223.183\n",
      "104.36.150.18\n",
      "23.227.38.74\n",
      "35.188.190.205\n",
      "89.163.146.94\n",
      "8.29.155.162\n",
      "184.24.10.132\n",
      "46.101.59.213\n",
      "23.185.0.1\n",
      "104.26.15.132\n",
      "172.64.153.173\n",
      "151.80.23.63\n",
      "54.227.239.44\n",
      "216.119.75.105\n",
      "212.100.250.155\n",
      "37.48.65.152\n",
      "172.67.181.131\n"
     ]
    }
   ],
   "source": [
    "# Adicionar contador para pausar a cada 100 registros\n",
    "# Adicionar colunas vazias ao DataFrame\n",
    "df['IP'] = ''\n",
    "df['DNS'] = ''\n",
    "df['Reverse DNS'] = ''\n",
    "df['n_dns'] = ''\n",
    "df['City'] = ''\n",
    "df['Region'] = ''\n",
    "df['Country'] = ''\n",
    "df['Org'] = ''\n",
    "df['Postal'] = ''\n",
    "df['Timezone'] = ''\n",
    "df['Hostname'] = ''\n",
    "df['Latitude'] = ''\n",
    "df['Longitude'] = ''\n",
    "\n",
    "# Adicionar contador para pausar a cada 100 registros\n",
    "for i in range(0, len(df), 100):\n",
    "    # Processar blocos de 100 registros\n",
    "    chunk = df.iloc[i:i+100].copy()\n",
    "\n",
    "    # Adicionar colunas para armazenar IP, DNS, Reverse DNS e número de DNS\n",
    "    chunk['IP'] = chunk['URL'].apply(lambda url: get_ip(url.split('//')[1]))\n",
    "    chunk['DNS'] = chunk['URL'].apply(lambda url: url.split('//')[1])\n",
    "    chunk['Reverse DNS'] = chunk['IP'].apply(get_reverse_dns)\n",
    "    chunk['n_dns'] = chunk['IP'].apply(get_dns_count)\n",
    "\n",
    "    # Obter informações de localização e adicionar colunas separadas\n",
    "    location_data = chunk['IP'].apply(get_location)\n",
    "    chunk['City'] = location_data.apply(lambda loc: loc['city'])\n",
    "    chunk['Region'] = location_data.apply(lambda loc: loc['region'])\n",
    "    chunk['Country'] = location_data.apply(lambda loc: loc['country'])\n",
    "    chunk['Org'] = location_data.apply(lambda loc: loc['org'])\n",
    "    chunk['Postal'] = location_data.apply(lambda loc: loc['postal'])\n",
    "    chunk['Timezone'] = location_data.apply(lambda loc: loc['timezone'])\n",
    "    chunk['Hostname'] = location_data.apply(lambda loc: loc['hostname'])\n",
    "    chunk['Latitude'] = location_data.apply(lambda loc: loc['latitude'])\n",
    "    chunk['Longitude'] = location_data.apply(lambda loc: loc['longitude'])\n",
    "\n",
    "    # Juntar o chunk ao DataFrame original\n",
    "    df.iloc[i:i+100] = chunk.copy()\n",
    "\n",
    "    print(f\"Processed chunk {i} to {i + 100}\")\n",
    "\n",
    "    if i > 0 and i % 100 == 0:\n",
    "        print(f\"Processed {i} records. Sleeping for 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "# Remover colunas não nomeadas\n",
    "df.drop(df.columns[df.columns.str.contains('Unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "# Salvar o resultado em um novo arquivo CSV\n",
    "df.to_csv('teste_reverse_dns.csv', index=False, sep=';')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código que não é usado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import pandas as pd\\nfrom sklearn.model_selection import train_test_split\\n\\n# Carregar o dataset\\ndf = pd.read_csv('PhishingDataset.csv', delimiter='')\\n\\n# Converter todas as colunas para strings\\ndf = df.astype(str)\\n\\n# Dividir o dataset em dois novos datasets (50% e 50%)\\ndf1, df2 = train_test_split(df, test_size=0.5, random_state=42)\\n\\n# Salvar os dois novos datasets em arquivos CSV separados\\ndf1.to_csv('dataset1.csv', index=False,sep=';')\\ndf2.to_csv('dataset2.csv', index=False,sep=';') \""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv('PhishingDataset.csv', delimiter='')\n",
    "\n",
    "# Converter todas as colunas para strings\n",
    "df = df.astype(str)\n",
    "\n",
    "# Dividir o dataset em dois novos datasets (50% e 50%)\n",
    "df1, df2 = train_test_split(df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Salvar os dois novos datasets em arquivos CSV separados\n",
    "df1.to_csv('dataset1.csv', index=False,sep=';')\n",
    "df2.to_csv('dataset2.csv', index=False,sep=';') \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import pandas as pd\\n\\n# Carregar o dataset com delimitador ';'\\ndf = pd.read_csv('Datasets/dataset1.csv', delimiter=';')\\n\\n# Calcular o número de linhas em 20% do dataset\\nn = len(df)\\nblock_size = int(n * 0.2)\\n\\n# Shuffle the dataset\\ndf_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\\n\\n# Create a list to hold each 20% block\\nblocks = []\\n\\n# Generate the 20% blocks\\nfor i in range(5):\\n    start_index = i * block_size\\n    end_index = (i + 1) * block_size\\n    block = df_shuffled.iloc[start_index:end_index]\\n    blocks.append(block)\\n    # Save each block to a new CSV file\\n    block.to_csv(f'Datasets/dataset_block_{i+1}.csv', index=False, sep=';')\\n\\n# In case the dataset size is not perfectly divisible by 5, add the remaining rows to the last block\\nif end_index < n:\\n    remaining_block = df_shuffled.iloc[end_index:]\\n    remaining_block.to_csv(f'Datasets/dataset_block_6.csv', index=False, sep=';')  \""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import pandas as pd\n",
    "\n",
    "# Carregar o dataset com delimitador ','\n",
    "df = pd.read_csv('Datasets/total.csv', delimiter=',')\n",
    "\n",
    "# Salvar o dataset com delimitador ';'\n",
    "df.to_csv('Datasets/total.csv', index=False, sep=';')  \"\"\"\n",
    "\n",
    "\"\"\" import pandas as pd\n",
    "\n",
    "# Carregar o dataset com delimitador ';'\n",
    "df = pd.read_csv('Datasets/dataset1.csv', delimiter=';')\n",
    "\n",
    "# Calcular o número de linhas em 20% do dataset\n",
    "n = len(df)\n",
    "block_size = int(n * 0.2)\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Create a list to hold each 20% block\n",
    "blocks = []\n",
    "\n",
    "# Generate the 20% blocks\n",
    "for i in range(5):\n",
    "    start_index = i * block_size\n",
    "    end_index = (i + 1) * block_size\n",
    "    block = df_shuffled.iloc[start_index:end_index]\n",
    "    blocks.append(block)\n",
    "    # Save each block to a new CSV file\n",
    "    block.to_csv(f'Datasets/dataset_block_{i+1}.csv', index=False, sep=';')\n",
    "\n",
    "# In case the dataset size is not perfectly divisible by 5, add the remaining rows to the last block\n",
    "if end_index < n:\n",
    "    remaining_block = df_shuffled.iloc[end_index:]\n",
    "    remaining_block.to_csv(f'Datasets/dataset_block_6.csv', index=False, sep=';')  \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
