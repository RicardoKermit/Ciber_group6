{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import socket\n",
    "import requests\n",
    "import dns.resolver\n",
    "import time\n",
    "\n",
    "# Função para obter o IP de um domínio\n",
    "def get_ip(domain):\n",
    "    try:\n",
    "        print (socket.gethostbyname(domain))\n",
    "        return socket.gethostbyname(domain)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Função para obter a localização do IP usando a API ipinfo.io\n",
    "def get_location(ip):\n",
    "    if ip:\n",
    "        try:\n",
    "            response = requests.get(f'https://ipinfo.io/{ip}/json?token=b90bb6976ece63')\n",
    "            data = response.json()\n",
    "            print(\"Aqui\",data)\n",
    "            loc = data.get('loc', '').split(',')\n",
    "            latitude = loc[0] if len(loc) > 0 else ''\n",
    "            longitude = loc[1] if len(loc) > 1 else ''\n",
    "            return {\n",
    "                'city': data.get('city', ''),\n",
    "                'region': data.get('region', ''),\n",
    "                'country': data.get('country', ''),\n",
    "                'org': data.get('org', ''),\n",
    "                'postal': data.get('postal', ''),\n",
    "                'timezone': data.get('timezone', ''),\n",
    "                'hostname': data.get('hostname', ''),\n",
    "                'latitude': latitude,\n",
    "                'longitude': longitude,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'city': '',\n",
    "                'region': '',\n",
    "                'country': '',\n",
    "                'org': '',\n",
    "                'postal': '',\n",
    "                'timezone': '',\n",
    "                'hostname': '',\n",
    "                'latitude': '',\n",
    "                'longitude': '',\n",
    "            }\n",
    "    return {\n",
    "        'city': '',\n",
    "        'region': '',\n",
    "        'country': '',\n",
    "        'org': '',\n",
    "        'postal': '',\n",
    "        'timezone': '',\n",
    "        'hostname': '',\n",
    "        'latitude': '',\n",
    "        'longitude': '',\n",
    "    }\n",
    "\n",
    "# Função para obter o DNS reverso de um IP\n",
    "def get_reverse_dns(ip):\n",
    "    if ip:\n",
    "        try:\n",
    "            return socket.gethostbyaddr(ip)[0]\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Função para obter o número de registros DNS de um IP\n",
    "def get_dns_count(ip):\n",
    "    if ip:\n",
    "        try:\n",
    "            answers = dns.resolver.resolve(ip, 'A')\n",
    "            return len(answers)\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ler dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Já corridos: \n",
    "    -dataset1_block6\n",
    "\n",
    "A correr:\n",
    "    -teste\n",
    "'''\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv('Datasets/teste.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linhas em que a label não se encontra preenchida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir valores vazios na coluna \"label\" por -1\n",
    "df['label'].fillna(-1, inplace=True)\n",
    "\n",
    "# Contar os valores únicos na coluna \"label\"\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Encontrar os índices das linhas com valor -1 na coluna \"label\"\n",
    "indices_to_drop = df[df['label'] == -1].index\n",
    "\n",
    "# Remover as linhas com valor -1 na coluna \"label\"\n",
    "df.drop(indices_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse module DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar contador para pausar a cada 100 registros\n",
    "# Adicionar colunas vazias ao DataFrame\n",
    "df['IP'] = ''\n",
    "df['DNS'] = ''\n",
    "df['Reverse DNS'] = ''\n",
    "df['n_dns'] = ''\n",
    "df['City'] = ''\n",
    "df['Region'] = ''\n",
    "df['Country'] = ''\n",
    "df['Org'] = ''\n",
    "df['Postal'] = ''\n",
    "df['Timezone'] = ''\n",
    "df['Hostname'] = ''\n",
    "df['Latitude'] = ''\n",
    "df['Longitude'] = ''\n",
    "\n",
    "# Adicionar contador para pausar a cada 100 registros\n",
    "for i in range(0, len(df), 100):\n",
    "    # Processar blocos de 100 registros\n",
    "    chunk = df.iloc[i:i+100].copy()\n",
    "\n",
    "    # Adicionar colunas para armazenar IP, DNS, Reverse DNS e número de DNS\n",
    "    chunk['IP'] = chunk['URL'].apply(lambda url: get_ip(url.split('//')[1]))\n",
    "    chunk['DNS'] = chunk['URL'].apply(lambda url: url.split('//')[1])\n",
    "    chunk['Reverse DNS'] = chunk['IP'].apply(get_reverse_dns)\n",
    "    chunk['n_dns'] = chunk['IP'].apply(get_dns_count)\n",
    "\n",
    "    # Obter informações de localização e adicionar colunas separadas\n",
    "    location_data = chunk['IP'].apply(get_location)\n",
    "    chunk['City'] = location_data.apply(lambda loc: loc['city'])\n",
    "    chunk['Region'] = location_data.apply(lambda loc: loc['region'])\n",
    "    chunk['Country'] = location_data.apply(lambda loc: loc['country'])\n",
    "    chunk['Org'] = location_data.apply(lambda loc: loc['org'])\n",
    "    chunk['Postal'] = location_data.apply(lambda loc: loc['postal'])\n",
    "    chunk['Timezone'] = location_data.apply(lambda loc: loc['timezone'])\n",
    "    chunk['Hostname'] = location_data.apply(lambda loc: loc['hostname'])\n",
    "    chunk['Latitude'] = location_data.apply(lambda loc: loc['latitude'])\n",
    "    chunk['Longitude'] = location_data.apply(lambda loc: loc['longitude'])\n",
    "\n",
    "    # Juntar o chunk ao DataFrame original\n",
    "    df.iloc[i:i+100] = chunk.copy()\n",
    "\n",
    "    print(f\"Processed chunk {i} to {i + 100}\")\n",
    "\n",
    "    if i > 0 and i % 100 == 0:\n",
    "        print(f\"Processed {i} records. Sleeping for 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "# Remover colunas não nomeadas\n",
    "df.drop(df.columns[df.columns.str.contains('Unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "# Salvar o resultado em um novo arquivo CSV\n",
    "df.to_csv('teste_reverse_dns.csv', index=False, sep=';')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código que não é usado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv('PhishingDataset.csv', delimiter='')\n",
    "\n",
    "# Converter todas as colunas para strings\n",
    "df = df.astype(str)\n",
    "\n",
    "# Dividir o dataset em dois novos datasets (50% e 50%)\n",
    "df1, df2 = train_test_split(df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Salvar os dois novos datasets em arquivos CSV separados\n",
    "df1.to_csv('dataset1.csv', index=False,sep=';')\n",
    "df2.to_csv('dataset2.csv', index=False,sep=';') \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import pandas as pd\n",
    "\n",
    "# Carregar o dataset com delimitador ','\n",
    "df = pd.read_csv('Datasets/total.csv', delimiter=',')\n",
    "\n",
    "# Salvar o dataset com delimitador ';'\n",
    "df.to_csv('Datasets/total.csv', index=False, sep=';')  \"\"\"\n",
    "\n",
    "\"\"\" import pandas as pd\n",
    "\n",
    "# Carregar o dataset com delimitador ';'\n",
    "df = pd.read_csv('Datasets/dataset1.csv', delimiter=';')\n",
    "\n",
    "# Calcular o número de linhas em 20% do dataset\n",
    "n = len(df)\n",
    "block_size = int(n * 0.2)\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Create a list to hold each 20% block\n",
    "blocks = []\n",
    "\n",
    "# Generate the 20% blocks\n",
    "for i in range(5):\n",
    "    start_index = i * block_size\n",
    "    end_index = (i + 1) * block_size\n",
    "    block = df_shuffled.iloc[start_index:end_index]\n",
    "    blocks.append(block)\n",
    "    # Save each block to a new CSV file\n",
    "    block.to_csv(f'Datasets/dataset_block_{i+1}.csv', index=False, sep=';')\n",
    "\n",
    "# In case the dataset size is not perfectly divisible by 5, add the remaining rows to the last block\n",
    "if end_index < n:\n",
    "    remaining_block = df_shuffled.iloc[end_index:]\n",
    "    remaining_block.to_csv(f'Datasets/dataset_block_6.csv', index=False, sep=';')  \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
